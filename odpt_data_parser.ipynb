{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "from datetime import datetime\n",
    "import time\n",
    "import json\n",
    "import urllib.request, json \n",
    "from collections import Counter \n",
    "import random\n",
    "import colorsys\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "api_url = 'https://api-tokyochallenge.odpt.org/api/v4/'\n",
    "api_url = 'https://api-tokyochallenge.odpt.org/api/v4/'\n",
    "api_token = '620ebb7c8bc13f982014fc2e69e856644f045897a5343175e929d86a82013cdb'\n",
    "\n",
    "tr_dict = {\n",
    "    \"共通\":\"Common\",\n",
    "    \"鉄道\":\"Train\",\n",
    "    \"バス\":\"Bus\",\n",
    "    \"航空機\":\"Aircraft\"\n",
    "}\n",
    "\n",
    "s_ref = [ref for ref in api_ref.split('\\n') if ref]\n",
    "api_endpoints = [{'type': tr_dict[s_ref[i]], \n",
    "                  'url':s_ref[i+1],\n",
    "                  'real_time': 'リアルタイム' in s_ref[i+3]} for i in range(0, len(s_ref), 4)]\n",
    "\n",
    "output_folder = 'C:/Users/umutk/Documents/Projects/odpt_2019/data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(output_folder):\n",
    "    shutil.rmtree(output_folder)\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "with open(output_folder + \"endpoints.json\", 'w', encoding='utf8') as f:\n",
    "    json.dump(api_endpoints, f)\n",
    "    \n",
    "for ep in tqdm(api_endpoints):\n",
    "    if not ep['real_time']: # only download static data for now\n",
    "        os.makedirs(f\"{output_folder}/{ep['type']}\", exist_ok=True)\n",
    "        req_url = (api_url + ep['url'] + '?acl:consumerKey=' + api_token if ep['real_time'] \n",
    "                    else api_url + ep['url'] + '.json?acl:consumerKey=' + api_token)\n",
    "                    \n",
    "        with urllib.request.urlopen(req_url) as url:\n",
    "            data = json.loads(url.read().decode())\n",
    "            with open(f\"{output_folder}/{ep['type']}/{ep['url'].replace(':', '_')}.json\", 'w+', encoding='utf8') as f:\n",
    "                json.dump(data, f, ensure_ascii=False)\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{output_folder}Common/odpt_Calendar.json\", encoding='utf8') as f:\n",
    "    print(json.dumps(json.load(f), indent=4, sort_keys=True, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{output_folder}Train/odpt_Railway.json\", encoding='utf8') as f:\n",
    "    railway = json.load(f)\n",
    "with open(f\"{output_folder}Train/odpt_Station.json\", encoding='utf8') as f:\n",
    "    station = json.load(f)\n",
    "with open(f\"{output_folder}Train/odpt_TrainTimetable.json\", encoding='utf8') as f:\n",
    "    train_time = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download color data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_web_color(url):\n",
    "    cw = requests.get(url)\n",
    "    soup = BeautifulSoup(cw.content)\n",
    "\n",
    "    result = []\n",
    "    for tr in soup.find_all(\"tr\"):\n",
    "        if tr.find_all(\"td\")[0].has_attr('style'):\n",
    "            result.append({'line_name': tr.find_all(\"td\")[1].getText(), \n",
    "                           'line_color': tr.find_all(\"td\")[0][\"style\"].split(\"; \")[0].split(\": \")[-1].replace(\";\", \"\").upper()})\n",
    "        else:\n",
    "            result[-1]['line_name'] += (', ' + tr.find_all(\"td\")[0].getText())\n",
    "        \n",
    "    return result\n",
    "\n",
    "url_colors = \"https://cdn.jsdelivr.net/npm/demo-dashi@0.2.1/src/line/tokyo.json\"\n",
    "with urllib.request.urlopen(url_colors) as url:\n",
    "    line_colors_scrape = json.loads(url.read().decode())\n",
    "line_colors_scrape = [l for g in line_colors_scrape['line_groups'] for l in g['lines']]\n",
    "\n",
    "line_colors_scrape.extend(scrape_web_color(\"https://ayaito.net/webtips/color_code/12224/\")) # kanto private railways\n",
    "line_colors_scrape.extend(scrape_web_color(\"https://ayaito.net/webtips/color_code/115/\")) # subways nationwide\n",
    "line_colors_scrape.extend(scrape_web_color(\"https://ayaito.net/webtips/color_code/164/\")) # JR group\n",
    "\n",
    "# outlier line color additions\n",
    "line_colors_scrape.extend([{'line_name': '中央線快速', 'line_color': '#f15a22'},\n",
    "                            {'line_name': '中央・総武各駅停車', 'line_color': '#ffd400'},\n",
    "                            {'line_name': '常磐線各駅停車', 'line_color': '#00b261'},\n",
    "                            {'line_name': '常磐線快速', 'line_color': '#339999'},\n",
    "                            {'line_name': '川越線(川越-高麗川間)', 'line_color': '#a8a39d'},\n",
    "                            {'line_name': '南武線浜川崎支線', 'line_color': '#ffd600'},\n",
    "                            {'line_name': '成田線我孫子支線', 'line_color': '#339999'},\n",
    "                            {'line_name': '埼京線・川越線', 'line_color': '#00ac9a'},\n",
    "                            {'line_name': '総武快速線', 'line_color': '#007ac0'},\n",
    "                            {'line_name': '鶴見線大川支線', 'line_color': '#ffd400'},\n",
    "                            {'line_name': '鶴見線海芝浦支線', 'line_color': '#ffd400'},\n",
    "                            {'line_name': '日暮里・舎人ライナー', 'line_color': '#0099cc'},\n",
    "                            {'line_name': '桐生線', 'line_color': '#FF0000'},\n",
    "                            {'line_name': '小泉線(東小泉-太田)', 'line_color': '#FF0000'},\n",
    "                            {'line_name': '小泉線', 'line_color': '#FF0000'},\n",
    "                            {'line_name': '佐野線', 'line_color': '#FF0000'},\n",
    "                            {'line_name': '東武スカイツリーライン(押上-曳舟)', 'line_color': '#0f6cc3'},\n",
    "                            {'line_name': '丸ノ内線支線', 'line_color': '#f62e36'},\n",
    "                            {'line_name': '会津線', 'line_color': '#006633'},\n",
    "                            {'line_name': '秩父本線', 'line_color': '#ff6600'},\n",
    "                            {'line_name': '芝山鉄道線', 'line_color': '#00a650'},\n",
    "                            {'line_name': '新京成線', 'line_color': '#EF59A1'},\n",
    "                            {'line_name': '会津鬼怒川線', 'line_color': '#ffa500 '},\n",
    "                            {'line_name': '駿豆線', 'line_color': '#0000ff'},\n",
    "                            {'line_name': 'ほくほく線', 'line_color': '#6633FF'},\n",
    "                            {'line_name': '西武秩父線', 'line_color': '#ff6600'},\n",
    "                            {'line_name': '西武園線', 'line_color': '#33cc66'},\n",
    "                            {'line_name': '水郡線', 'line_color': '#368c44'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_colors = {}\n",
    "\n",
    "for r in railway:\n",
    "    rw_name = r['dc:title']\n",
    "    match = list(filter(lambda lc: lc['line_name'] in rw_name\n",
    "                        or rw_name in lc['line_name'].replace(\", \", \n",
    "                                                              \"・\").translate({ord(ch):'・' \n",
    "                                                                              for ch in '＜＞（）'}).split(\"・\")\n",
    "                        or rw_name == lc['line_name'].replace('東武鉄道', '').replace('東武', '').replace('東京メトロ','')\n",
    "                        or rw_name.replace(\"線\",\"鉄道\") in lc['line_name']\n",
    "                        or rw_name.replace(\"線\",\"本線\") in lc['line_name'], line_colors_scrape))\n",
    "    \n",
    "    if match:\n",
    "        line_colors[r['owl:sameAs']] = match[0]['line_color'].upper()\n",
    "len(line_colors), len(railway)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{output_folder}Train/line_colors.json\", 'w+', encoding='utf8') as f:\n",
    "    json.dump(line_colors, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_bright_color():\n",
    "    h,s,l = random.random(), 0.5 + random.random()/2.0, 0.4 + random.random()/5.0\n",
    "    r,g,b = [int(256*i) for i in colorsys.hls_to_rgb(h,l,s)]\n",
    "\n",
    "    return f'#{r:02X}{g:02X}{b:02X}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_line_color(r):\n",
    "    return line_colors[r['owl:sameAs']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{output_folder}Train/line_colors.json\", encoding='utf8') as f:\n",
    "    line_colors = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing useful data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def railway_station_lookup(rw_code):\n",
    "    r = [r for r in railway if r['owl:sameAs']==rw_code][0]\n",
    "    return {st['odpt:station']: st['odpt:index'] for st in r['odpt:stationOrder']} if 'odpt:stationOrder' in r else false\n",
    "\n",
    "def station_railway_lookup(rw_code):\n",
    "    r = [r for r in railway if r['owl:sameAs']==rw_code][0]\n",
    "    return {st['odpt:index']: st['odpt:station'] for st in r['odpt:stationOrder']} if 'odpt:stationOrder' in r else false\n",
    "\n",
    "def get_timetable(calendar):\n",
    "    result = {}\n",
    "    for tt in train_time:\n",
    "        if tt['odpt:calendar'] == calendar:\n",
    "            _timetable = [{'i':  railway_station_lookup(tt[\"odpt:railway\"])[(stt[\"odpt:departureStation\"] \n",
    "                                               if \"odpt:departureStation\" in stt\n",
    "                                               else stt[\"odpt:arrivalStation\"])], \n",
    "                          't': (stt[\"odpt:departureTime\"] \n",
    "                                       if \"odpt:departureTime\" in stt\n",
    "                                       else stt[\"odpt:arrivalTime\"])}\n",
    "                                 for stt in tt[\"odpt:trainTimetableObject\"]\n",
    "                                 if (\"odpt:departureStation\" in stt and \"odpt:departureTime\" in stt) \n",
    "                                 or (\"odpt:arrivalStation\" in stt and \"odpt:arrivalTime\" in stt)]\n",
    "            \n",
    "            # filter some values to keep file size small\n",
    "            if len(_timetable) > 10:\n",
    "                start, end = _timetable[0]['t'], _timetable[-1]['t']\n",
    "                end = end if end>start else f\"{int(end.split(':')[0]) + 24}:{end.split(':')[1]}\"\n",
    "                \n",
    "                result[tt[\"odpt:railway\"]] = result.get(tt[\"odpt:railway\"], []) + [{\n",
    "                    \"n\": tt[\"odpt:trainNumber\"],\n",
    "                    \"type\": tt[\"odpt:trainType\"].split(\":\")[-1],\n",
    "                    \"tt\": _timetable,\n",
    "                    \"int\": [start, end]\n",
    "                     }]\n",
    "    \n",
    "    return result\n",
    "\n",
    "timetable_weekday = get_timetable('odpt.Calendar:Weekday')\n",
    "with open(f\"{output_folder}Train/train_timetable_weekday.json\", 'w+', encoding='utf8') as f:\n",
    "    json.dump(timetable_weekday, f, ensure_ascii=False)\n",
    "\n",
    "timetable_holiday = get_timetable('odpt.Calendar:SaturdayHoliday')\n",
    "with open(f\"{output_folder}Train/train_timetable_holiday.json\", 'w+', encoding='utf8') as f:\n",
    "    json.dump(timetable_holiday, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{output_folder}Train/train_timetable_weekday.json\", encoding='utf8') as f:\n",
    "    timetable = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rail_station_times = [{\"-\".join(sorted([station_railway_lookup(tk)[ts1['i']], station_railway_lookup(tk)[ts2['i']]])):\n",
    "                       (datetime.strptime(ts2['t'], '%H:%M') -  datetime.strptime(ts1['t'], '%H:%M')).seconds}\n",
    "                      for tk, tv in timetable.items() \n",
    "                      for ttv in tv \n",
    "                      for ts1,ts2 in zip(ttv['tt'], ttv['tt'][1:])]\n",
    "st_dist={}\n",
    "for rs_pair in tqdm(rail_station_times):\n",
    "    key, val = list(rs_pair.items())[0]\n",
    "    st_dist[key] = st_dist.get(key, []) + [val] \n",
    "st_dist = {k : int(sum(v)/len(v)) for k, v in st_dist.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = []\n",
    "for r in tqdm(railway):\n",
    "    stations = []\n",
    "    for idx, rs in enumerate(r['odpt:stationOrder']):\n",
    "        st_info = next((s for s in station \n",
    "                        if rs['odpt:station'] == s[\"owl:sameAs\"]\n",
    "                        or (rs['odpt:station'].split('.')[-2:] == s[\"owl:sameAs\"][-2:]\n",
    "                            and r['owl:sameAs'] in s.get('odpt:connectingRailway', []))\n",
    "                       ), None)\n",
    "        if st_info and 'geo:lat' in st_info:\n",
    "            passing_trains = st_info.get('odpt:connectingRailway', []) + [st_info['odpt:railway']]\n",
    "            stations.append({\n",
    "                'idx': rs['odpt:index'], \n",
    "                'code': rs['odpt:station'],\n",
    "                 # 'st_code': st_info['odpt:stationCode'] if 'odpt:stationCode' in st_info else '',\n",
    "                'title': st_info['odpt:stationTitle']['en'], \n",
    "                'dur': 0 if rs['odpt:station'] == r['odpt:stationOrder'][-1]['odpt:station'] \n",
    "                else st_dist.get('-'.join(sorted([rs['odpt:station'], r['odpt:stationOrder'][idx+1]['odpt:station']])), 180),\n",
    "                # 'title_ja': st_info['odpt:stationTitle']['ja'],\n",
    "                'geo': {'lat': st_info['geo:lat'], 'long': st_info['geo:long']},\n",
    "                'trains': passing_trains\n",
    "            })\n",
    "    stations = sorted(stations, key=lambda k: k['idx'])\n",
    "\n",
    "    if len(stations)>2:\n",
    "        line.append({\n",
    "            'code': r['owl:sameAs'], \n",
    "            'title': r['odpt:railwayTitle']['en'], \n",
    "             # 'title_ja': r['odpt:railwayTitle']['ja'],\n",
    "             # 'repr_color': get_line_color(r),\n",
    "            'station': stations\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save station coordinates for lines\n",
    "line = [l for l in line if 'station' in l and len(l['station']) > 1]\n",
    "with open(f\"{output_folder}Train/line_station_coords.json\", 'w+', encoding='utf8') as f:\n",
    "                json.dump(line, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(f\"{output_folder}Train/line_station_coords.json\", encoding='utf8') as f:\n",
    "    line = json.load(f)\n",
    "    print(json.dumps(line[0], indent=4, sort_keys=True, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
